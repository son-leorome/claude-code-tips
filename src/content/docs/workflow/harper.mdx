---
title: My LLM codegen workflow atm
description: A reference page in my new Starlight docs site.
---
### Step 1 - Idea honing

Use a conversational LLM to hone in on an idea (I use ChatGPT 4o / o3 for this):

```
Ask me one question at a time so we can develop a thorough, step-by-step spec for this idea. Each question should build on my previous answers, and our end goal is to have a detailed specification I can hand off to a developer. Let’s do this iteratively and dig into every relevant detail. Remember, only one question at a time.

Here’s the idea:

<IDEA>
```

At the end of the brainstorm (it will come to a natural conclusion):

```
Now that we’ve wrapped up the brainstorming process, can you compile our findings into a comprehensive, developer-ready specification? Include all relevant requirements, architecture choices, data handling details, error handling strategies, and a testing plan so a developer can immediately begin implementation.
```
This will output a pretty solid and straightforward spec that can be handed off to the planning step. I like to save it as `spec.md` in the repo.

```
You can use this spec for a number of things. We are doing codegen here, but I have used it to bolster ideas by asking a reasoning model to poke holes in the idea (must go deeper!), to generate a white paper, or to generate a business model. You can pop it into deep research and get a 10k word supporting document in return.
```

### Step 2 - Planning

Take the spec and pass it to a proper reasoning model (o1*, o3*, r1):

(This is the TDD prompt)
```
Draft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. Review the results and make sure that the steps are small enough to be implemented safely with strong testing, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.

From here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step in a test-driven manner. Prioritize best practices, incremental progress, and early testing, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.

Make sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.

<SPEC>
```

(This is the non-tdd prompt)

```
Draft a detailed, step-by-step blueprint for building this project. Then, once you have a solid plan, break it down into small, iterative chunks that build on each other. Look at these chunks and then go another round to break it into small steps. review the results and make sure that the steps are small enough to be implemented safely, but big enough to move the project forward. Iterate until you feel that the steps are right sized for this project.

From here you should have the foundation to provide a series of prompts for a code-generation LLM that will implement each step. Prioritize best practices, and incremental progress, ensuring no big jumps in complexity at any stage. Make sure that each prompt builds on the previous prompts, and ends with wiring things together. There should be no hanging or orphaned code that isn't integrated into a previous step.

Make sure and separate each prompt section. Use markdown. Each prompt should be tagged as text using code tags. The goal is to output prompts, but context, etc is important as well.

<SPEC>
```
It should output a prompt plan that you can execute with aider, cursor, etc. I like to save this as `prompt_plan.md` in the repo.

I then have it output a `todo.md` that can be checked off.

```
Can you make a `todo.md` that I can use as a checklist? Be thorough.
```

You can save it as todo.md in the repo.

Your codegen tool should be able to check off the `todo.md` while processing. This is good for keeping state across sessions.

**Yay. Plan!**

Now you have a robust plan and documentation that will help you execute and build your project.

This entire process will take maybe **15 minutes**. It is pretty quick. Wild tbh.



### Step 3 - Implementation (this is a bit outdated since the author posted as of Feb 2025)
There are so many options available for execution. The success really depends on how well step 2 went.

I have used this workflow with [github workspace](https://githubnext.com/projects/copilot-workspace), [aider](https://aider.chat/), [cursor](https://cursor.com/agents), [claude engineer](https://github.com/Doriandarko/claude-engineer), [sweep.dev](https://sweep.dev/), [chatgpt](https://chatgpt.com/), [claude.ai](https://claude.ai/new), etc. It works pretty well with all the tools I have tried, and I imagine it will work well with any codegen tool.

I, however, prefer **raw** claude and aider:

#### Claude
I essentially pair program with [claude.ai](https://claude.ai/new) and just drop each prompt in iteratively. I find that works pretty well. The back and forth can be annoying, but it largely works.

I am in charge of the initial boilerplate code, and making sure tooling is set up correctly. This allows for some freedom, choice, and guidance in the beginning. Claude has a tendency to just output react code - and having a solid foundation with the language, style, and tooling of your choice will help quite a bit.

I will then use a tool like [repomix](https://github.com/yamadashy/repomix) to iterate when things get stuck (more about that later).

The workflow is like this:

* set up the repo (boilerplate, uv init, cargo init, etc)
* paste in prompt into claude
* copy and paste code from claude.ai into IDE
* run code, run tests, etc
…
if it works, move on to next prompt
if it doesn’t work, use repomix to pass the codebase to claude to debug
rinse repeat ✩₊˚.⋆☾⋆⁺₊✧

#### Aider
[Aider](https://aider.chat/) is fun and weird to use. I find that it slots in well to the output of step 2. I can get really far with very little work.

The workflow is essentially the same as above but instead of pasting into claude, I am pasting the prompts into aider.

Aider will then “just do it” and I get to play [cookie clicker](https://orteil.dashnet.org/cookieclicker/).


`
An aside: Aider does really great benchmarking of new models for codegen in their [LLM leaderboards](https://aider.chat/docs/leaderboards/). I find it to be a really great resource for seeing how effective new models are.
`


Testing is nice with aider, because it can be even more hands off as aider will run the test suite and debug things for you.

The workflow is like this:

* set up the repo (boilerplate, uv init, cargo init, etc)
* start aider
* paste prompt into aider
* watch aider dance ♪┏(・o･)┛♪
* aider will run tests, or you can run app to verify
* if it works, move on to next prompt
* if it doesn’t work, Q&A with aider to fix
* rinse repeat ✩₊˚.⋆☾⋆⁺₊✧

#### Results

I have built so so many things using this workflow: scripts, expo apps, rust cli tools, etc. It has worked across programming languages, and contexts. I do like it.

If you have a small or large project that you are procrastinating on, I would recommend giving it a shot. You will be surprised how far you can get in a short amount of time.

My hack to-do list is empty because I built everything. I keep thinking of new things and knocking them out while watching a movie or something. For the first time in years, I am spending time with new programming languages and tools. This is pushing me to expand my programming perspective.







### Reference

[My LLM codegen workflow atm
](https://harper.blog/2025/02/16/my-llm-codegen-workflow-atm/)